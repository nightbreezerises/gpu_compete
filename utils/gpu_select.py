"""
GPU Select - GPU é€‰æ‹©ç­–ç•¥æ¨¡å—
æ ¹æ®æ˜¾å­˜åˆ©ç”¨ç‡å’Œæ˜¾å­˜çŠ¶æ€é€‰æ‹©æœ€ä¼˜GPU

é€‰æ‹©ç­–ç•¥ï¼š
- èŠ‚çœæ˜¾å­˜æ¨¡å¼ï¼ˆmemory_save_mode=Trueï¼‰ï¼š
  æ˜¾å­˜åˆ©ç”¨ç‡*å‰©ä½™æ˜¾å­˜ è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜
  å¦‚æœç›¸ç­‰ï¼Œé‚£ä¹ˆå‰©ä½™æ˜¾å­˜è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜
  
- é˜²æ­¢æ˜¾å­˜æº¢å‡ºæ¨¡å¼ï¼ˆmemory_save_mode=Falseï¼‰ï¼š
  æ˜¾å­˜åˆ©ç”¨ç‡*å½“å‰å ç”¨æ˜¾å­˜ è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜
  å¦‚æœç›¸ç­‰ï¼Œé‚£ä¹ˆå½“å‰å ç”¨æ˜¾å­˜è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜
"""

import time
import subprocess
import logging
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass


@dataclass
class GPUStats:
    """GPU ç»Ÿè®¡ä¿¡æ¯"""
    gpu_id: int
    memory_free: float      # å‰©ä½™æ˜¾å­˜ (GB)
    memory_used: float      # å·²ç”¨æ˜¾å­˜ (GB)
    memory_total: float     # æ€»æ˜¾å­˜ (GB)
    utilization: float      # GPU åˆ©ç”¨ç‡ (0-100)
    
    @property
    def memory_utilization(self) -> float:
        """æ˜¾å­˜åˆ©ç”¨ç‡ (0-1)"""
        if self.memory_total > 0:
            return self.memory_used / self.memory_total
        return 0.0


class GPUSelector:
    """GPU é€‰æ‹©å™¨
    
    æ ¹æ®é…ç½®çš„ç­–ç•¥é€‰æ‹©æœ€ä¼˜GPU
    æ”¯æŒé«˜é¢‘é‡‡æ ·å–å¹³å‡å€¼ä»¥è·å¾—æ›´ç¨³å®šçš„ç»“æœ
    """
    
    def __init__(self, memory_save_mode: bool = True):
        """åˆå§‹åŒ–
        
        Args:
            memory_save_mode: True=èŠ‚çœæ˜¾å­˜æ¨¡å¼, False=é˜²æ­¢æ˜¾å­˜æº¢å‡ºæ¨¡å¼
        """
        self.memory_save_mode = memory_save_mode
    
    @staticmethod
    def get_gpu_stats(gpu_id: int) -> Optional[GPUStats]:
        """è·å–å•ä¸ªGPUçš„ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            gpu_id: GPU ID
            
        Returns:
            GPUStats å¯¹è±¡ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            result = subprocess.run(
                ['nvidia-smi', '--query-gpu=memory.free,memory.used,memory.total,utilization.gpu',
                 '--format=csv,noheader,nounits', f'--id={gpu_id}'],
                capture_output=True, text=True, timeout=5
            )
            if result.returncode == 0:
                parts = result.stdout.strip().split(',')
                if len(parts) >= 4:
                    return GPUStats(
                        gpu_id=gpu_id,
                        memory_free=float(parts[0].strip()) / 1024,  # MB -> GB
                        memory_used=float(parts[1].strip()) / 1024,  # MB -> GB
                        memory_total=float(parts[2].strip()) / 1024,  # MB -> GB
                        utilization=float(parts[3].strip())  # 0-100
                    )
        except Exception as e:
            logging.debug(f"Failed to get stats for GPU {gpu_id}: {e}")
        return None
    
    @staticmethod
    def get_all_gpu_stats(gpu_ids: List[int]) -> Dict[int, GPUStats]:
        """è·å–å¤šä¸ªGPUçš„ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            gpu_ids: GPU ID åˆ—è¡¨
            
        Returns:
            {gpu_id: GPUStats} å­—å…¸
        """
        stats = {}
        for gpu_id in gpu_ids:
            gpu_stats = GPUSelector.get_gpu_stats(gpu_id)
            if gpu_stats:
                stats[gpu_id] = gpu_stats
        return stats
    
    def sample_gpu_stats(self, gpu_ids: List[int], 
                         sample_count: int = 30, 
                         sample_interval: float = 0.1) -> Dict[int, GPUStats]:
        """é«˜é¢‘é‡‡æ ·GPUç»Ÿè®¡ä¿¡æ¯å¹¶å–å¹³å‡å€¼
        
        åœ¨3ç§’å†…é‡‡æ ·30æ¬¡ï¼ˆæ¯0.1ç§’é‡‡æ ·ä¸€æ¬¡ï¼‰ï¼Œå–å¹³å‡å€¼
        
        Args:
            gpu_ids: GPU ID åˆ—è¡¨
            sample_count: é‡‡æ ·æ¬¡æ•°ï¼Œé»˜è®¤30æ¬¡
            sample_interval: é‡‡æ ·é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤0.1ç§’
            
        Returns:
            {gpu_id: GPUStats} å­—å…¸ï¼Œå€¼ä¸ºå¹³å‡ç»Ÿè®¡ä¿¡æ¯
        """
        if not gpu_ids:
            return {}
        
        # å­˜å‚¨æ‰€æœ‰é‡‡æ ·æ•°æ®
        samples: Dict[int, List[GPUStats]] = {gpu_id: [] for gpu_id in gpu_ids}
        
        logging.info(f"ğŸ” å¼€å§‹GPUé‡‡æ ·: {sample_count}æ¬¡, é—´éš”{sample_interval}ç§’, æ€»æ—¶é•¿{sample_count * sample_interval:.1f}ç§’")
        
        for i in range(sample_count):
            for gpu_id in gpu_ids:
                stats = self.get_gpu_stats(gpu_id)
                if stats:
                    samples[gpu_id].append(stats)
            
            # æœ€åä¸€æ¬¡ä¸éœ€è¦ç­‰å¾…
            if i < sample_count - 1:
                time.sleep(sample_interval)
        
        # è®¡ç®—å¹³å‡å€¼
        avg_stats = {}
        for gpu_id, stats_list in samples.items():
            if not stats_list:
                continue
            
            n = len(stats_list)
            avg_stats[gpu_id] = GPUStats(
                gpu_id=gpu_id,
                memory_free=sum(s.memory_free for s in stats_list) / n,
                memory_used=sum(s.memory_used for s in stats_list) / n,
                memory_total=stats_list[0].memory_total,  # æ€»æ˜¾å­˜ä¸å˜
                utilization=sum(s.utilization for s in stats_list) / n
            )
            
            logging.debug(f"GPU {gpu_id} å¹³å‡å€¼: free={avg_stats[gpu_id].memory_free:.2f}GB, "
                         f"used={avg_stats[gpu_id].memory_used:.2f}GB, "
                         f"util={avg_stats[gpu_id].utilization:.1f}%")
        
        return avg_stats
    
    def calculate_priority(self, stats: GPUStats) -> Tuple[float, float]:
        """è®¡ç®—GPUä¼˜å…ˆçº§åˆ†æ•°
        
        Args:
            stats: GPUç»Ÿè®¡ä¿¡æ¯
            
        Returns:
            (ä¸»ä¼˜å…ˆçº§åˆ†æ•°, æ¬¡ä¼˜å…ˆçº§åˆ†æ•°)
            åˆ†æ•°è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜
        """
        # æ˜¾å­˜åˆ©ç”¨ç‡ (0-1)
        mem_util = stats.memory_utilization
        
        if self.memory_save_mode:
            # èŠ‚çœæ˜¾å­˜æ¨¡å¼ï¼šæ˜¾å­˜åˆ©ç”¨ç‡*å‰©ä½™æ˜¾å­˜ è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜
            # å¦‚æœç›¸ç­‰ï¼Œé‚£ä¹ˆå‰©ä½™æ˜¾å­˜è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜
            primary_score = mem_util * stats.memory_free
            secondary_score = stats.memory_free
        else:
            # é˜²æ­¢æ˜¾å­˜æº¢å‡ºæ¨¡å¼ï¼šæ˜¾å­˜åˆ©ç”¨ç‡*å½“å‰å ç”¨æ˜¾å­˜ è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜
            # å¦‚æœç›¸ç­‰ï¼Œé‚£ä¹ˆå½“å‰å ç”¨æ˜¾å­˜è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜
            primary_score = mem_util * stats.memory_used
            secondary_score = stats.memory_used
        
        return (primary_score, secondary_score)
    
    def select_best_gpu(self, gpu_ids: List[int], 
                        required_memory: float = 0,
                        use_sampling: bool = True,
                        sample_count: int = 30,
                        sample_interval: float = 0.1) -> Optional[int]:
        """é€‰æ‹©æœ€ä¼˜GPU
        
        Args:
            gpu_ids: å€™é€‰GPU IDåˆ—è¡¨
            required_memory: éœ€è¦çš„æ˜¾å­˜ (GB)ï¼Œç”¨äºè¿‡æ»¤æ˜¾å­˜ä¸è¶³çš„GPU
            use_sampling: æ˜¯å¦ä½¿ç”¨é«˜é¢‘é‡‡æ ·
            sample_count: é‡‡æ ·æ¬¡æ•°
            sample_interval: é‡‡æ ·é—´éš”ï¼ˆç§’ï¼‰
            
        Returns:
            æœ€ä¼˜GPU IDï¼Œå¦‚æœæ²¡æœ‰å¯ç”¨GPUè¿”å›None
        """
        if not gpu_ids:
            return None
        
        # è·å–GPUç»Ÿè®¡ä¿¡æ¯
        if use_sampling:
            stats_dict = self.sample_gpu_stats(gpu_ids, sample_count, sample_interval)
        else:
            stats_dict = self.get_all_gpu_stats(gpu_ids)
        
        if not stats_dict:
            logging.warning("æ— æ³•è·å–ä»»ä½•GPUçš„ç»Ÿè®¡ä¿¡æ¯")
            return None
        
        # è¿‡æ»¤æ˜¾å­˜ä¸è¶³çš„GPU
        valid_gpus = []
        for gpu_id, stats in stats_dict.items():
            if stats.memory_free >= required_memory:
                valid_gpus.append((gpu_id, stats))
            else:
                logging.debug(f"GPU {gpu_id} æ˜¾å­˜ä¸è¶³: {stats.memory_free:.2f}GB < {required_memory}GB")
        
        if not valid_gpus:
            logging.warning(f"æ²¡æœ‰GPUæ»¡è¶³æ˜¾å­˜éœ€æ±‚ {required_memory}GB")
            return None
        
        # è®¡ç®—ä¼˜å…ˆçº§å¹¶æ’åº
        scored_gpus = []
        for gpu_id, stats in valid_gpus:
            primary, secondary = self.calculate_priority(stats)
            scored_gpus.append((gpu_id, stats, primary, secondary))
            
            mode_name = "èŠ‚çœæ˜¾å­˜" if self.memory_save_mode else "é˜²æ­¢æº¢å‡º"
            logging.info(f"GPU {gpu_id} [{mode_name}æ¨¡å¼]: "
                        f"free={stats.memory_free:.2f}GB, used={stats.memory_used:.2f}GB, "
                        f"util={stats.utilization:.1f}%, mem_util={stats.memory_utilization:.2%}, "
                        f"score=({primary:.4f}, {secondary:.4f})")
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆåˆ†æ•°è¶Šå°è¶Šä¼˜å…ˆï¼‰
        scored_gpus.sort(key=lambda x: (x[2], x[3]))
        
        best_gpu_id = scored_gpus[0][0]
        best_stats = scored_gpus[0][1]
        
        logging.info(f"âœ… é€‰æ‹©GPU {best_gpu_id}: free={best_stats.memory_free:.2f}GB, "
                    f"util={best_stats.utilization:.1f}%")
        
        return best_gpu_id
    
    def select_best_gpus(self, gpu_ids: List[int],
                         count: int,
                         required_memory: float = 0,
                         use_sampling: bool = True,
                         sample_count: int = 30,
                         sample_interval: float = 0.1) -> List[int]:
        """é€‰æ‹©å¤šä¸ªæœ€ä¼˜GPU
        
        Args:
            gpu_ids: å€™é€‰GPU IDåˆ—è¡¨
            count: éœ€è¦é€‰æ‹©çš„GPUæ•°é‡
            required_memory: æ¯ä¸ªGPUéœ€è¦çš„æ˜¾å­˜ (GB)
            use_sampling: æ˜¯å¦ä½¿ç”¨é«˜é¢‘é‡‡æ ·
            sample_count: é‡‡æ ·æ¬¡æ•°
            sample_interval: é‡‡æ ·é—´éš”ï¼ˆç§’ï¼‰
            
        Returns:
            æœ€ä¼˜GPU IDåˆ—è¡¨ï¼Œå¯èƒ½å°‘äºè¯·æ±‚æ•°é‡
        """
        if not gpu_ids or count <= 0:
            return []
        
        # è·å–GPUç»Ÿè®¡ä¿¡æ¯
        if use_sampling:
            stats_dict = self.sample_gpu_stats(gpu_ids, sample_count, sample_interval)
        else:
            stats_dict = self.get_all_gpu_stats(gpu_ids)
        
        if not stats_dict:
            logging.warning("æ— æ³•è·å–ä»»ä½•GPUçš„ç»Ÿè®¡ä¿¡æ¯")
            return []
        
        # è¿‡æ»¤æ˜¾å­˜ä¸è¶³çš„GPU
        valid_gpus = []
        for gpu_id, stats in stats_dict.items():
            if stats.memory_free >= required_memory:
                valid_gpus.append((gpu_id, stats))
            else:
                logging.debug(f"GPU {gpu_id} æ˜¾å­˜ä¸è¶³: {stats.memory_free:.2f}GB < {required_memory}GB")
        
        if not valid_gpus:
            logging.warning(f"æ²¡æœ‰GPUæ»¡è¶³æ˜¾å­˜éœ€æ±‚ {required_memory}GB")
            return []
        
        # è®¡ç®—ä¼˜å…ˆçº§å¹¶æ’åº
        scored_gpus = []
        for gpu_id, stats in valid_gpus:
            primary, secondary = self.calculate_priority(stats)
            scored_gpus.append((gpu_id, stats, primary, secondary))
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆåˆ†æ•°è¶Šå°è¶Šä¼˜å…ˆï¼‰
        scored_gpus.sort(key=lambda x: (x[2], x[3]))
        
        # é€‰æ‹©å‰countä¸ªGPU
        selected = [gpu_id for gpu_id, _, _, _ in scored_gpus[:count]]
        
        if selected:
            logging.info(f"âœ… é€‰æ‹© {len(selected)} ä¸ªGPU: {selected}")
        
        return selected


def select_gpu(gpu_ids: List[int], 
               memory_save_mode: bool = True,
               required_memory: float = 0,
               use_sampling: bool = True) -> Optional[int]:
    """ä¾¿æ·å‡½æ•°ï¼šé€‰æ‹©å•ä¸ªæœ€ä¼˜GPU
    
    Args:
        gpu_ids: å€™é€‰GPU IDåˆ—è¡¨
        memory_save_mode: True=èŠ‚çœæ˜¾å­˜æ¨¡å¼, False=é˜²æ­¢æ˜¾å­˜æº¢å‡ºæ¨¡å¼
        required_memory: éœ€è¦çš„æ˜¾å­˜ (GB)
        use_sampling: æ˜¯å¦ä½¿ç”¨é«˜é¢‘é‡‡æ ·ï¼ˆ3ç§’30æ¬¡ï¼‰
        
    Returns:
        æœ€ä¼˜GPU IDï¼Œå¦‚æœæ²¡æœ‰å¯ç”¨GPUè¿”å›None
    """
    selector = GPUSelector(memory_save_mode=memory_save_mode)
    return selector.select_best_gpu(
        gpu_ids=gpu_ids,
        required_memory=required_memory,
        use_sampling=use_sampling
    )


def select_gpus(gpu_ids: List[int],
                count: int,
                memory_save_mode: bool = True,
                required_memory: float = 0,
                use_sampling: bool = True) -> List[int]:
    """ä¾¿æ·å‡½æ•°ï¼šé€‰æ‹©å¤šä¸ªæœ€ä¼˜GPU
    
    Args:
        gpu_ids: å€™é€‰GPU IDåˆ—è¡¨
        count: éœ€è¦é€‰æ‹©çš„GPUæ•°é‡
        memory_save_mode: True=èŠ‚çœæ˜¾å­˜æ¨¡å¼, False=é˜²æ­¢æ˜¾å­˜æº¢å‡ºæ¨¡å¼
        required_memory: æ¯ä¸ªGPUéœ€è¦çš„æ˜¾å­˜ (GB)
        use_sampling: æ˜¯å¦ä½¿ç”¨é«˜é¢‘é‡‡æ ·ï¼ˆ3ç§’30æ¬¡ï¼‰
        
    Returns:
        æœ€ä¼˜GPU IDåˆ—è¡¨
    """
    selector = GPUSelector(memory_save_mode=memory_save_mode)
    return selector.select_best_gpus(
        gpu_ids=gpu_ids,
        count=count,
        required_memory=required_memory,
        use_sampling=use_sampling
    )
